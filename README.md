# FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>


# Projeto: fiap_gs1

## Atividade em Grupo: FIAP - 1TIAOB - 2025/1 - Fase4 GS1

## üë®‚Äçüéì Integrantes: 
- <a href="">Alice C. M. Assis - RM 566233</a>
- <a href="">Leonardo S. Souza - RM 563928</a>
- <a href="">Lucas B. Francelino - RM 561409</a> 
- <a href="">Pedro L. T. Silva - RM 561644</a> 
- <a href="">Vitor A. Bezerra - RM 563001</a>

## üë©‚Äçüè´ Professores:
### Tutor(a) 
- <a href="proflucas.moreira@fiap.com.br">Lucas Gomes Moreira</a>
### Coordenador(a)
- <a href="profandre.chiovato@fiap.com.br">Andr√© Godoi Chiovato</a>

## üåç Escolha do Evento Extremo e Base de Dados Utilizada

Para o desenvolvimento deste projeto, o grupo escolheu focar no desastre natural ocorrido em 29 de abril de 2024: Enchente no Brasil. Este evento extremo foi selecionado por sua relev√¢ncia e impacto significativo nas regi√µes afetadas, tornando-se um caso de estudo ideal para a aplica√ß√£o de t√©cnicas de previs√£o e monitoramento.

Como base de dados para o treinamento e valida√ß√£o do modelo de IA, utilizamos as informa√ß√µes disponibilizadas gratuitamente pelo site disasterscharter.org. Essa plataforma re√∫ne dados reais de desastres globais, incluindo imagens de sat√©lite, relat√≥rios t√©cnicos e registros oficiais monitorados por ag√™ncias internacionais. O uso dessas informa√ß√µes garante que o modelo tenha acesso a dados confi√°veis e atualizados para a constru√ß√£o de previs√µes mais precisas e eficazes.

## üìú Descri√ß√£o

## Projeto: Neura5: Agente de IA para Comunica√ß√£o Emergencial em Desastres

Confira o v√≠deo de apresenta√ß√£o do projeto clicando no link(imagem) abaixo:

[![Neura5](assets/readme/logo.jpeg)](https://www.youtube.com/watch?v=STebZkIM680)

## Introdu√ß√£o

Nos √∫ltimos anos, o IPCC documentou que eventos de precipita√ß√£o intensa aumentam em cerca de **7% a cada 1 ¬∞C de aquecimento**, resultando em inunda√ß√µes mais severas e frequentes. Esse agravamento se reflete em dados regionais: entre 2000 e 2023, a **EM-DAT registrou 505 desastres hidrol√≥gicos** na Am√©rica do Sul, com **mais de 10 694 √≥bitos**. No Brasil, as enchentes de janeiro de 2020 **deslocaram entre 30 000 e 46 500 pessoas** e causaram pelo menos **70 mortes**.

Ao mesmo tempo, √≥rg√£os de resposta como a **Defesa Civil e o Corpo de Bombeiros enfrentam limita√ß√µes log√≠sticas, escassez de recursos e d√©ficit de pessoal**, especialmente em √°reas urbanas densas. Nessa situa√ß√£o, a comunica√ß√£o emergencial ‚Äî essencial para orientar evacua√ß√µes preventivas ‚Äî torna-se imprescind√≠vel, pois **informa√ß√µes claras e precisas podem reduzir significativamente o n√∫mero de v√≠timas**. A r√°pida propaga√ß√£o de not√≠cias falsas em redes sociais torna ainda mais urgente dispor de meios confi√°veis, eficazes e √°geis de divulga√ß√£o.

Diante desse contexto, desenvolvemos um **agente de intelig√™ncia artificial** que incorpora **um modelo de previs√£o de enchentes** treinado com dados hist√≥ricos e leituras de sensores, al√©m de **gerar automaticamente conte√∫dos informativos e alertas**. O objetivo √© **otimizar tempo e recursos das equipes de emerg√™ncia**, garantindo que orienta√ß√µes essenciais cheguem de forma r√°pida e eficaz √† popula√ß√£o em risco. Adicionalmente, propomos futuramente a **cria√ß√£o de um aplicativo m√≥vel** que incluir√° funcionalidades de suporte a buscas e resgates em situa√ß√µes de desastre**, como **monitoramento de √°reas de risco**, **detec√ß√£o de perda de sinal suspeita** e **notifica√ß√£o autom√°tica de autoridades**.

## O Problema

O principal desafio consiste em estabelecer uma comunica√ß√£o eficiente e assertiva, capaz de rivalizar com a rapidez das redes sociais e de combater a prolifera√ß√£o de informa√ß√µes falsas. Al√©m disso, caso a mensagem n√£o seja apresentada de forma atrativa, √© prov√°vel que parcela significativa da popula√ß√£o n√£o a leia, comprometendo a√ß√µes de seguran√ßa essenciais.

Em situa√ß√µes de crise, a popula√ß√£o necessita de **orienta√ß√µes claras** e imediatas sobre procedimentos de autoprote√ß√£o, locais de abrigo e medidas a serem adotadas para garantir a seguran√ßa individual e coletiva.

Portanto, √© imprescind√≠vel que a comunica√ß√£o seja **visualmente impactante**, utilizando imagens e recursos gr√°ficos que transmitam a urg√™ncia dos fatos e as instru√ß√µes necess√°rias de maneira r√°pida e de f√°cil compreens√£o. Muitos cidad√£os podem n√£o ter acesso a textos longos ou apresentar dificuldades de leitura em momentos de estresse. Por esse motivo, o uso de elementos visuais apropriados torna-se fundamental para ampliar o alcance e a efic√°cia das mensagens.

## MVP da Solu√ß√£o Proposta

**Desenvolvemos um Agente de Intelig√™ncia Artificial** voltado para a **gera√ß√£o autom√°tica de publica√ß√µes e imagens informativas** que possam ser utilizadas em tempo real pelos canais de comunica√ß√£o da **Defesa Civil** e do **Corpo de Bombeiros**. Essa solu√ß√£o atua como **suporte operacional**, produzindo conte√∫dos **em tempo real** fundamentados em **dados concretos sobre desastres em curso ou iminentes**. O principal objetivo √© **aumentar a velocidade e a precis√£o na divulga√ß√£o de alertas e orienta√ß√µes** √† popula√ß√£o em regi√µes de risco.

As funcionalidades principais do agente incluem:

- **Gera√ß√£o de posts informativos e alertas**: Utilizando **dados captados por sensores ambientais** e **previs√µes meteorol√≥gicas**, o agente elabora **mensagens claras e objetivas** sobre o n√≠vel de risco, orienta√ß√µes de seguran√ßa e medidas preventivas.
- **Cria√ß√£o de imagens ilustrativas**: Para refor√ßar o **impacto visual**, o sistema gera **imagens** que permitem √† popula√ß√£o **compreender rapidamente a gravidade da situa√ß√£o** e as a√ß√µes recomendadas.
- **Integra√ß√£o com APIs de previs√£o do tempo**: O agente consulta **servi√ßos externos de meteorologia** para obter **informa√ß√µes atualizadas sobre condi√ß√µes clim√°ticas**, essenciais para **antecipar eventos adversos**.
- **Modelo preditivo de enchentes**: Baseado em **dados hist√≥ricos, leituras atuais de sensores e vari√°veis ambientais**, o sistema emprega um **modelo de IA treinado pelo grupo** para **estimar a probabilidade de ocorr√™ncia de enchentes** em regi√µes espec√≠ficas.

Dessa forma, o agente oferece um **conjunto de ferramentas** que aprimoram significativamente a **capacidade de comunica√ß√£o das equipes de emerg√™ncia**, permitindo que a popula√ß√£o seja bem informada e consiga evitar incidentes graves com anteced√™ncia.

## Tecnologias Utilizadas

- **Machine Learning em Python:** An√°lise de dados ambientais e gera√ß√£o contextual de mensagens de alerta.

- **ESP32 com sensor ambiental:** Coleta de dados locais (ex.: n√≠vel de √°gua) para criar posts baseados em dados em tempo real.

- **Base de dados reais:** Utiliza√ß√£o de informa√ß√µes da plataforma [disasterscharter.org](https://disasterscharter.org), que re√∫ne imagens de sat√©lite e relat√≥rios globais sobre desastres. Para treinamento do modelo de IA e cria√ß√£o de prova de conceito, foi utilizado o dataset fornecido pela Ag√™ncia Nacional de √Åguas e Saneamento B√°sico (ANA), dispon√≠vel no seguinte [link](https://github.com/anagovbr/hidro-dados-estacoes-convencionais/tree/main).

- **Banco de Dados:** Armazenamento e organiza√ß√£o de mensagens geradas, registros de risco e hist√≥ricos.

- **Streamlit:** Desenvolvimento de um dashboard interativo para visualiza√ß√£o e gest√£o dos dados, permitindo que as equipes de emerg√™ncia acessem rapidamente as informa√ß√µes geradas pelo agente.

- **API de previs√£o do tempo:** Integra√ß√£o com servi√ßos meteorol√≥gicos para fornecer dados atualizados sobre condi√ß√µes clim√°ticas, essenciais para a gera√ß√£o de alertas precisos.

- **Wokwi:** Simula√ß√£o do ESP32 para monitoramento de condi√ß√µes ambientais, possibilitando a cria√ß√£o de posts informativos baseados em dados reais.

- **FAST API:** Cria√ß√£o de uma api b√°sica para salvar os dados das leituras geradas pela simua√ß√£o do Wokwi

## Resultados Esperados

- Aumento significativo da **agilidade e efic√°cia na comunica√ß√£o** de riscos e procedimentos de seguran√ßa;
- **Evacua√ß√£o mais r√°pida** e coordenada das comunidades amea√ßadas;
- Redu√ß√£o da necessidade de a√ß√µes log√≠sticas de alto custo e complexas em situa√ß√µes com alta demanda por recursos;
- Suporte pr√°tico √†s opera√ß√µes de campo com **alertas visualmente otimizados** e de f√°cil replica√ß√£o;
- Ferramenta expans√≠vel para campanhas preventivas e treinamentos.

---

## Upgrades para o Futuro
Com o objetivo de tornar o agente cada vez mais eficiente e relevante em situa√ß√µes de emerg√™ncia, foram identificadas diversas possibilidades de evolu√ß√£o da solu√ß√£o desenvolvida:

- **Gera√ß√£o de √°udio e v√≠deo:** A expans√£o do agente para criar conte√∫dos multim√≠dia, como v√≠deos curtos e mensagens de voz, pode ser mais eficaz em alcan√ßar p√∫blicos diversos. Apesar disso, devido a limita√ß√µes or√ßament√°rias, a vers√£o inicial se concentra em posts est√°ticos e imagens. Ainda assim, o grupo utilizou a IA VEO3 para produzir v√≠deos da apresenta√ß√£o, demonstrando o potencial da ferramenta para futuros desdobramentos.

- **Integra√ß√£o com sistemas de alerta:** Conectar o agente a plataformas de alerta em massa ‚Äî como sirenes comunit√°rias, SMS e aplicativos de mensagens ‚Äî pode garantir que as informa√ß√µes cheguem rapidamente √† popula√ß√£o em risco, ampliando o alcance das comunica√ß√µes.

- **An√°lise de sentimento e feedback:** Implementar mecanismos de an√°lise de sentimento nas redes sociais e nas intera√ß√µes com o agente permitir√° entender melhor como a popula√ß√£o reage √†s mensagens, possibilitando ajustes em tempo real nas estrat√©gias de comunica√ß√£o.

- **Melhoria do modelo de previs√£o de enchentes:** Com a incorpora√ß√£o de dados adicionais (como dados meteorol√≥gicos em tempo real e imagens de sat√©lite) e feedback direto das equipes de emerg√™ncia, o modelo pode ser continuamente aperfei√ßoado, aumentando a precis√£o das previs√µes.

- **An√°lise de dados hist√≥ricos:** Capacitar o agente para estudar dados hist√≥ricos de desastres naturais pode ajudar na identifica√ß√£o de padr√µes, melhorando a antecipa√ß√£o de riscos e o planejamento de campanhas informativas futuras.

- **Expans√£o para outras √°reas:** A arquitetura do agente pode ser adaptada para atuar em outras crises, como pandemias, surtos de doen√ßas, inc√™ndios florestais ou acidentes tecnol√≥gicos, ampliando sua utilidade como ferramenta de comunica√ß√£o p√∫blica.

- **Localiza√ß√£o e personaliza√ß√£o:** Permitir que o agente gere conte√∫dos personalizados conforme a localiza√ß√£o do usu√°rio √© uma evolu√ß√£o importante. Com isso, mensagens podem ser adaptadas para refletir a gravidade da situa√ß√£o em cada regi√£o, aumentando a relev√¢ncia e efic√°cia das orienta√ß√µes.

## (IR AL√âM) üöÄ Pr√≥ximos Passos e Vis√£o Futura: Expans√£o para Aplicativo M√≥vel

Al√©m dos upgrades para o futoro anteriormente citado, visando ampliar ainda mais o impacto e a efic√°cia da solu√ß√£o desenvolvida, propomos a evolu√ß√£o do projeto para um aplicativo m√≥vel robusto e proativo. O objetivo √© ir al√©m da comunica√ß√£o reativa, oferecendo um sistema de monitoramento individualizado e preditivo, voltado √† preven√ß√£o de desaparecimentos em cen√°rios de desastre. A ideia √© ir al√©m da comunica√ß√£o passiva e reativa, oferecendo uma camada adicional de prote√ß√£o √† vida humana por meio de an√°lise preditiva, geolocaliza√ß√£o e intelig√™ncia de rede.

**üöÄ Vis√£o Geral**

O aplicativo atua de forma proativa ao:

- Monitorar a localiza√ß√£o do usu√°rio em tempo real;
- Validar m√∫ltiplas fontes de risco e alertas oficiais;
- Detectar padr√µes suspeitos de perda de sinal celular;
- Acionar automaticamente as autoridades se todos os crit√©rios forem atendidos.

**üîç Funcionamento T√©cnico**

O sistema baseia-se em tr√™s etapas principais de verifica√ß√£o simult√¢nea:

1. Monitoramento de √Årea de Risco

- Verifica se o usu√°rio se encontra em uma regi√£o georreferenciada de risco (enchentes, queimadas, deslizamentos, etc.);
- Consulta bases cartogr√°ficas oficiais e dados meteorol√≥gicos em tempo real.

2. Confirma√ß√£o de Desastre em Andamento
Integra dados de fontes confi√°veis como:

- Defesa Civil
- INMET
- Alertas do governo

Valida se h√° evento ativo na regi√£o monitorada.

3. An√°lise Inteligente da Perda de Sinal
Parceria com operadoras nacionais para detectar:

- Perda de sinal considerada normal (bateria, desligamento manual, modo avi√£o);
- Perda de sinal suspeita (dano por √°gua, queimaduras, impacto f√≠sico, aus√™ncia de sinal em √°rea com cobertura);
- Utiliza√ß√£o de metadados e padr√µes da rede em conformidade com a LGPD.

**‚ö†Ô∏è Acionamento Autom√°tico**

Se as tr√™s condi√ß√µes forem verificadas simultaneamente, o sistema:

‚úÖ Detecta o usu√°rio em uma √°rea de risco ativa

‚úÖ Confirma a ocorr√™ncia de desastre na regi√£o

‚úÖ Identifica uma perda de sinal anormal

‚û°Ô∏è Aciona automaticamente as autoridades competentes, enviando:

- √öltima localiza√ß√£o registrada;
- Hor√°rio e tipo de perda de sinal;
- Dados contextuais sobre o evento natural detectado.

**üí° Impacto Esperado**

Aumento da efici√™ncia no resgate de desaparecidos;

- Redu√ß√£o do tempo de resposta das autoridades;
- Maior efic√°cia nas buscas;
- Diminui√ß√£o no n√∫mero de v√≠timas n√£o localizadas;
- Amplia√ß√£o da prote√ß√£o a popula√ß√µes vulner√°veis;
- Suporte direto √†s opera√ß√µes de campo.

**üìà Futuras Expans√µes**

- Integra√ß√£o com alertas via SMS, sirenes locais e apps oficiais;
- Hist√≥rico offline de alertas, rotas de fuga e pontos seguros;
- Modo "compartilhar localiza√ß√£o" com contatos de confian√ßa;
- Painel administrativo para acompanhamento por equipes de resgate.

**üõ°Ô∏è Conformidade e Privacidade**

Todos os dados tratados seguem a Lei Geral de Prote√ß√£o de Dados (LGPD).

- Os dados de localiza√ß√£o s√£o coletados apenas com consentimento do usu√°rio.
- Nenhuma informa√ß√£o pessoal √© exposta ou comercializada.
- Os metadados utilizados para an√°lise de sinal s√£o processados de forma anonimizada, focando exclusivamente em identificar situa√ß√µes de risco.

**ü§ù Integra√ß√£o com a Solu√ß√£o de IA**

Este aplicativo comp√µe uma segunda camada tecnol√≥gica no ecossistema proposto pelo grupo:

Enquanto o agente de IA se encarrega da comunica√ß√£o massiva,

O app m√≥vel foca em a√ß√µes individuais e automatizadas de resposta emergencial,
trabalhando de forma complementar e coordenada.

---

## Sobre o projeto

O projeto foi desenvolvido com foco em usabilidade f√°cil e intuitiva, permitindo que as equipes de emerg√™ncia possam gerar e compartilhar informa√ß√µes rapidamente, mesmo sob press√£o. A interface do dashboard foi projetada para ser simples e direta, priorizando a visualiza√ß√£o clara dos dados e a gera√ß√£o r√°pida de posts informativos.

### 1Ô∏è‚É£ Circuito de sensores

<p align="center">
  <img src="assets/readme/circuito_sensor.JPG" alt="Circuito Sensor" border="0" width=70% height=70%>
</p>

O grupo desenvolveu um circuito de sensores utilizando o ESP32, que coleta dados ambientais em tempo real e executa a√ß√µes autom√°ticas de alerta. O funcionamento do sistema est√° detalhado no arquivo [sketch.cpp](src/wokwi/src/sketch.cpp), que implementa toda a l√≥gica de leitura dos sensores, tomada de decis√£o e comunica√ß√£o com a API.

#### Componentes do circuito

- **LDR (Sensor de luminosidade):** Simula o n√≠vel de √°gua do bueiro, conectado ao pino anal√≥gico 32 (`#define LDR_PIN 32`).
- **HC-SR04 (Sensor ultrass√¥nico):** Mede a dist√¢ncia at√© a superf√≠cie da √°gua (leito do rio), usando os pinos 25 (ECHO) e 26 (TRIG).
- **Bot√£o:** Simula a resposta de uma API meteorol√≥gica, conectado ao pino 18.
- **LED:** Indica o envio de dados e alerta de n√≠veis cr√≠ticos, no pino 2.
- **Rel√©:** Aciona uma bomba d'√°gua em caso de alerta, no pino 4.
- **Buzzer:** Emite alerta sonoro quando n√≠veis cr√≠ticos s√£o detectados, no pino 23.

#### Funcionamento do c√≥digo

1. **Defini√ß√£o dos pinos e configura√ß√£o inicial:**
   Os pinos dos sensores e atuadores s√£o definidos no in√≠cio do c√≥digo:
   ```cpp
   #define LDR_PIN      32
   #define RELAY_PIN    4
   #define LED_PIN      2
   #define BUTTON_API   18
   #define ECHO_PIN     25
   #define TRIG_PIN     26
   #define BUZZER_PIN   23
   ```
   No `setup()`, cada pino √© configurado conforme sua fun√ß√£o (entrada ou sa√≠da), e o Wi-Fi √© conectado:
   ```cpp
   void setup() {
     // ...configura√ß√£o dos pinos...
     conectaWiFi();
   }
   ```

2. **Leitura dos sensores:**
   - O valor do LDR √© lido com `analogRead(LDR_PIN)`, simulando o n√≠vel do bueiro.
   - A dist√¢ncia do HC-SR04 √© obtida pela fun√ß√£o `readDistanceCM()`, que dispara o pulso ultrass√¥nico e calcula a dist√¢ncia:
     ```cpp
     float readDistanceCM() {
       // ...envio do pulso...
       int duration = pulseIn(ECHO_PIN, HIGH);
       return duration * 0.034 / 2;
     }
     ```
   - O bot√£o √© lido com `digitalRead(BUTTON_API)` para simular a resposta da API meteorol√≥gica.

3. **Processamento e decis√£o:**
   O c√≥digo avalia se os n√≠veis est√£o cr√≠ticos:
   ```cpp
   bool nivelBueiroCritico = (ldrValue > 3000);
   bool nivelLeitoCritico = (distance > 300);
   ```
   Se qualquer condi√ß√£o cr√≠tica for detectada, ou se o bot√£o for pressionado, o sistema ativa o alerta:
   ```cpp
   if (condicoesCriticas >= 1 or leituraAPIMetereologica == LOW) {
     digitalWrite(RELAY_PIN, HIGH);  // Liga a bomba
     digitalWrite(LED_PIN, HIGH);    // Liga o LED
     // Sequ√™ncia de tons no buzzer
   }
   ```

4. **A√ß√µes de alerta:**
   - O rel√© e o LED s√£o acionados para indicar o alerta.
   - O buzzer emite uma sequ√™ncia de tons usando a fun√ß√£o `tone()`:
     ```cpp
     tone(BUZZER_PIN, 261); delay(100);
     // ...outros tons...
     noTone(BUZZER_PIN);
     ```

5. **Envio de dados para a API:**
   Os dados coletados s√£o enviados para a API via HTTP POST, utilizando a fun√ß√£o `post_data()`:
   ```cpp
   int post_data(JsonDocument& doc, const String& endpoint_api) {
     // ...envio do JSON para a API...
   }
   ```
   O JSON inclui o n√∫mero de s√©rie do sensor, valores de leitura e estado do rel√©.

6. **Loop principal:**
   O `loop()` executa continuamente a leitura dos sensores, toma decis√µes de alerta e envia os dados para a API a cada 2 segundos:
   ```cpp
   void loop() {
     // ...leitura, decis√£o, alerta e envio...
     delay(2000);
   }
   ```

Dessa forma, o circuito simulado no Wokwi representa fielmente um sistema de monitoramento de enchentes, realizando leituras peri√≥dicas, acionando alertas autom√°ticos e registrando os dados em um backend para an√°lise posterior.

## Conex√£o com o wifi e envio de dados para a API

Para que a simula√ß√£o funcione corretamente, √© necess√°rio configurar a conex√£o com Wi-Fi simulado do Wokwi em como, configurar o IP do servidor local da API.
No momento, neste MVP a api e a simula√ß√£o do ESP32 est√£o rodando localmente. 
Para a confirgura√ß√£o funcionar corretamente, √© necess√°rio alterar o arquivo [platformio.ini](src/wokwi/platformio.ini) e setar a v√°riavel 'API_URL' para 'http://**IP DE SUA M√ÅQUINA NA REDE LOCAL**:8180' conforme exemplo abaixo:

```plaintext
[env:esp32]
platform = espressif32
framework = arduino
board = esp32dev
lib_deps = 
    bblanchon/ArduinoJson@^7.4.1
build_flags = 
    '-D API_URL="http://192.168.0.60:8180"'
    '-D NETWORK_SSID="Wokwi-GUEST"'
    '-D NETWORK_PASSWORD=""'
```

>NOTA1: N√£o sete o ip da API para localhost ou 127.0.0.1 pois o ESP32 n√£o conseguir√° se conectar a ele, pois o localhost do ESP32 √© o pr√≥prio ESP32 e n√£o a m√°quina onde o servidor est√° rodando.

>NOTA2: Caso voc√™ esteja rodando a simula√ß√£o e mesmo assim o ESP32 n√£o consiga se conectar a API, verifique se o firewall da sua m√°quina est√° bloqueando a porta 8180, caso esteja, libere a porta para que o ESP32 consiga se conectar.


Ap√≥s configurado o arquivo `platformio.ini`, voc√™ poder√° iniciar a simula√ß√£o do ESP32 no Wokwi. O circuito ir√° coletar os dados dos sensores e envi√°-los para a API, que por sua vez ir√° armazenar os dados no banco de dados.

## API para salvar os dados do sensor

Neste MVP, foi implementada uma API b√°sica utilizando o FastAPI para receber os dados do sensor e armazen√°-los no banco de dados. A API permite que o ESP32 envie as leituras dos sensores, que s√£o ent√£o salvas no banco de dados para posterior an√°lise e visualiza√ß√£o.
Para facilitar os testes, a API est√° configurada para rodar localmente na porta 8180 e ser√° iniciada automaticamente junto ao dashboard ao executar o comando `streamlit run main_dash.py` quando a vari√°vel de ambiente `ENABLE_API` for setada como `true`.
No entanto, caso queira, a api pode ser executada separadamente executando o arquivo [api_basica.py](src/wokwi_api/api_basica.py).

Explica√ß√µes mais detalhadas sobre como iniciar o dashboard e vari√°veis de ambiente ser√£o apresentadas na se√ß√£o "INSTALANDO E EXECUTANDO O PROJETO", a seguir neste mesmo README.md.


## Funcionamento da API "init_sensor"

  # Funcionamento:
    Recebe uma Requisi√ß√£o
    A requisi√ß√£o deve conter um campo serial no corpo JSON, representando o n√∫mero de s√©rie √∫nico do sensor.

  # Verifica e Cria Tipos de Sensores
    Para cada valor do TipoSensorEnum, o script verifica se j√° existe um tipo correspondente no banco de dados.
    Se o tipo ainda n√£o existir, ele √© criado e persistido.

  # Verifica Exist√™ncia de Sensor
    Antes de cadastrar um novo sensor, o script verifica se j√° existe um sensor com o mesmo n√∫mero de s√©rie (serial) e o mesmo tipo.
    Se j√° existir, o sensor n√£o √© recriado (evita duplicatas).

  # Cria√ß√£o do Sensor
    Caso o sensor ainda n√£o exista, ele √© criado com:
      Nome no formato Sensor <tipo> - <serial>
      Serial fornecido pela requisi√ß√£o
      Tipo de sensor associado
      Descri√ß√£o padr√£o

  # Resposta da API
    Ao final do processo, retorna um JSON com status de sucesso e uma mensagem confirmando o cadastro.

  # Exemplo requisi√ß√£o:
    POST /init
    {
      "serial": "ABC123"
    }

  # Exemplo de resposta:
    {
      "status": "success",
      "message": "Sensor cadastrado com sucesso."
    }


## Funcionamento da API "receber_leitura"

  # Funcionamento:
    Recebe uma requisi√ß√£o POST contendo um JSON com os seguintes campos:
      - serial: n√∫mero de s√©rie do sensor (obrigat√≥rio)
      - bueiro: valor da leitura do sensor de bueiro (opcional)
      - leito: valor da leitura do sensor de leito (opcional)
      - rele: estado do rel√© (opcional, n√£o utilizado no armazenamento)

  # Busca do Sensor:
    A API procura no banco de dados todos os sensores cadastrados com o serial informado.

    - Se nenhum sensor for encontrado, retorna um erro informando que o sensor n√£o foi localizado.

  # Identifica√ß√£o do Tipo de Sensor:
    Para cada sensor encontrado, a API identifica o tipo (BUEIRO ou LEITO).

    - Se o tipo for BUEIRO e o campo "bueiro" estiver presente na requisi√ß√£o, √© criada uma nova leitura com esse valor.
    - Se o tipo for LEITO e o campo "leito" estiver presente na requisi√ß√£o, √© criada uma nova leitura com esse valor.
    - Caso contr√°rio, n√£o √© criada leitura para aquele sensor.

  # Armazenamento:
    As leituras v√°lidas s√£o salvas no banco de dados com a data/hora atual.

  # Resposta da API:
    Ap√≥s o processamento, retorna um JSON indicando sucesso ou erro.

  # Exemplo de requisi√ß√£o:
    POST /receber_leitura
    {
      "serial": "ABC123",
      "bueiro": 100,
      "leito": 380.05,
      "rele": false
    }

  # Exemplo de resposta:
    {
      "status": "success",
      "message": "Leitura recebida com sucesso"
    }



### 2Ô∏è‚É£ Armazenamento de Dados em Banco SQL com Python

O armazenamento dos dados coletados pelos sensores foi implementado em Python, utilizando um banco de dados SQL. O c√≥digo √© respons√°vel por criar tabelas, inserir dados e realizar opera√ß√µes CRUD (Criar, Ler, Atualizar e Deletar) no banco de dados.

## MER

<p align="center">
  <img src="assets/mer.png" alt="MER" border="0" width=70% height=70%>
</p>



Modelo de Entidade-Relacionamento:

Tabela: TIPO_SENSOR
  - id (INTEGER NOT NULL) [PK]
  - nome (VARCHAR(255) NOT NULL)
  - tipo (VARCHAR(15) NOT NULL)

Tabela: SENSOR
  - id (INTEGER NOT NULL) [PK]
  - tipo_sensor_id (INTEGER NOT NULL) [FK -> TIPO_SENSOR]
  - nome (VARCHAR(255))
  - cod_serial (VARCHAR(255))
  - descricao (VARCHAR(255))
  - data_instalacao (DATETIME)
  - latitude (FLOAT)
  - longitude (FLOAT)

Tabela: LEITURA_SENSOR
  - id (INTEGER NOT NULL) [PK]
  - sensor_id (INTEGER NOT NULL) [FK -> SENSOR]
  - data_leitura (DATETIME NOT NULL)
  - valor (FLOAT NOT NULL)

Tabela: ARQUIVO
  - id (INTEGER NOT NULL) [PK]
  - nome (VARCHAR(255) NOT NULL)
  - tipo (VARCHAR(15) NOT NULL)
  - ultima_atualizacao (DATETIME)
  - bytes_arquivo (BLOB NOT NULL)

Tabela: POST_REDE_SOCIAL
  - id (INTEGER NOT NULL) [PK]
  - conteudo (TEXT NOT NULL)
  - ultima_atualizacao (DATETIME)
  - anexo_id (INTEGER) [FK -> ARQUIVO]

### üóÉÔ∏è Justificativa para a Escolha da Estrutura de Dados

A escolha de um banco de dados relacional foi fundamentada nos seguintes aspectos:

- **Integridade e Consist√™ncia:**  
  O modelo relacional assegura que os dados permane√ßam √≠ntegros e consistentes, o que √© especialmente importante em cen√°rios cr√≠ticos, como situa√ß√µes de emerg√™ncia.

- **Relacionamento entre Dados:**  
  A organiza√ß√£o em tabelas com chaves prim√°rias e estrangeiras permite mapear de forma clara as rela√ß√µes entre sensores, tipos, leituras, arquivos e posts. Isso facilita a realiza√ß√£o de consultas complexas e o cruzamento de informa√ß√µes.

- **Normaliza√ß√£o e Redu√ß√£o de Redund√¢ncia:**  
  A utiliza√ß√£o de tabelas normalizadas evita a duplicidade de informa√ß√µes, tornando o armazenamento mais eficiente e a manuten√ß√£o dos dados mais simples e segura.

- **Consultas Eficientes e Flex√≠veis:**  
  OA linguagem SQL possibilita a execu√ß√£o de consultas r√°pidas e personalizadas, essenciais para an√°lises hist√≥ricas, gera√ß√£o de relat√≥rios e tomada de decis√£o em tempo real.

- **Escalabilidade e Facilidade de Manuten√ß√£o:**  
  O modelo relacional √© facilmente expans√≠vel, permitindo a adi√ß√£o de novos tipos de sensores, arquivos ou funcionalidades sem comprometer a estrutura existente.

- **Compatibilidade com o Ecossistema Python:**  
  A integra√ß√£o com bibliotecas amplamente utilizadas no ambiente Python, como SQLAlchemy e Pandas, facilita o desenvolvimento, a an√°lise e a visualiza√ß√£o dos dados.

- **Integra√ß√£o com Ferramentas de Visualiza√ß√£o:**  
  A estrutura relacional favorece a conex√£o com dashboards e ferramentas de Business Intelligence, potencializando o aproveitamento dos dados coletados.

## Models e Python

Para realizar a convers√£o das linhas e colunas da database para Python, foram definidas classes as quais s√£o respons√°veis por fazer as opera√ß√µes CRUD e demais funcionalidades do banco de dados.
Essas classes podem ser encontradas na pasta `src/database/models`, e todas elas herdam a classe principal chamada [Model](src/database/tipos_base/model.py)

---

### 3Ô∏è‚É£ INSTALANDO E EXECUTANDO O PROJETO

O sistema foi desenvolvido em Python e utiliza um banco de dados Oracle para armazenar os dados. O c√≥digo √© modularizado, permitindo f√°cil manuten√ß√£o e expans√£o.

## üì¶ Requisitos
- Python 3.13.2
- Bibliotecas:
  - oracledb==3.1.0
  - pandas==2.2.3
  - matplotlib==3.10.1
  - streamlit==1.44.1
  - SQLAlchemy==2.0.40
  - google-genai==1.17.0
  - dotenv==0.9.9
  - pillow==11.2.1
  - fastapi==0.115.12
  - pydantic==2.11.5
  - uvicorn==0.34.3
  - plotly==6.1.2
  - scikit-learn==1.6.1
  - joblib==1.5.1

## üìÇ Instala√ß√£o

- Instale as depend√™ncias utilizando o arquivo requirements.txt:
    ```bash
    pip install -r requirements.txt
    ```
  
- Para iniciar o dashboard interativo, execute o seguinte comando no terminal:
    ```bash
    streamlit run main_dash.py
    ```

## Arquivo de Configura√ß√£o

O projeto utiliza um arquivo especial denominado **`.env`** para armazenar vari√°veis de ambiente sens√≠veis, como credenciais de banco de dados e chaves de APIs externas. Por raz√µes de seguran√ßa, esse arquivo **n√£o deve ser compartilhado publicamente**.

### üìÑ O que √© o `.env`?

O `.env` √© um arquivo-texto simples, onde cada linha define uma vari√°vel de ambiente no formato `NOME_VARIAVEL=valor`. Esse m√©todo permite separar informa√ß√µes confidenciais do c√≥digo-fonte, facilitando a configura√ß√£o do sistema para diferentes ambientes (desenvolvimento, testes, produ√ß√£o, etc).

### üîë Vari√°veis Utilizadas

| Vari√°vel      | Descri√ß√£o                                                                                                | Exemplo de Valor                  |
|---------------|----------------------------------------------------------------------------------------------------------|-----------------------------------|
| GEMINI_API    | Chave da API do Google GenAI (Gemini)                                                                    | `AIza...`                         |
| API_MET       | Chave da API do OpenWeather                                                                              | `b1c2...`                         |
| SQL_LITE      | Define o banco de dados a ser usado (`true` ou `false`)                                                  | `true` ou `false`                 |
| LOGGING_ENABLED      | Define se o logger da aplica√ß√£o ser√° ativado (`true` ou `false`)                                         | `true` ou `false`                 |
| ENABLE_API      | Define se a API que salva os dados do sensor ser√° ativada juntamente com o dashboard (`true` ou `false`) | `true` ou `false`                 |

### üöÄ Como obter suas chaves de API

> ATEN√á√ÉO: Um arquivo `.env` foi enviado diretamente ao orientador contendo todas as chaves da API. Caso voc√™ queria rodar o projeto e n√£o seja o orientador, ser√° necess√°rio obter suas pr√≥prias chaves das API.

- **GEMINI_API:**  
  Crie uma conta no [Google AI Studio](https://aistudio.google.com/app/apikey) e gere sua chave para o Google GenAI.
- **API_MET:**  
  Cadastre-se no [OpenWeather](https://openweathermap.org) e gere sua chave de API.

### ‚öôÔ∏è Exemplo de arquivo `.env`

```plaintext
GEMINI_API=sua_chave_gemini_aqui
API_MET=sua_chave_openweather_aqui
SQL_LITE=true
LOGGING_ENABLED=true
ENABLE_API=true
```

- Se `SQL_LITE=true`, o sistema usar√° o banco SQLite local.
- Se `SQL_LITE=false`, ser√° utilizado o banco Oracle da FIAP (o sistema apresentar√° uma tela de login para colocar o usu√°rio e senha do banco de dados).

> üí° **ATEN√á√ÉO:**  
> Para o sistema funcionar corretamente √© necess√°rio criar o arquivo [.env](.env) na raiz do projeto, e fornecer as chaves das apis supracitadas.

### 4Ô∏è‚É£ Vis√£o Geral do Sistema

Ao executar o sistema, se foi setado o SQL_LITE como `false`, primeiramente voc√™ ver√° uma tela de login para inserir o usu√°rio e senha do banco de dados Oracle da FIAP. Ap√≥s o login, voc√™ ter√° acesso ao dashboard, onde poder√° visualizar os dados coletados pelos sensores, gerar posts informativos e monitorar as condi√ß√µes ambientais em tempo real.

## Login

<p align="center">
  <img src="assets/readme/dashboard/login.JPG" alt="login" border="0" width=70% height=70%>
</p>

> Preencha o usu√°rio e senha do banco de dados Oracle da FIAP para acessar o dashboard.
 
## Gera√ß√£o de posts para redes sociais

Ao entrar no sistema, o usu√°rio ser√° direcionado para a p√°gina de gera√ß√£o de posts, onde poder√° criar posts informativos com base nos dados coletados pelos sensores e nas condi√ß√µes ambientais atuais.
A l√≥gica do agente de IA est√° dividida em v√°rios arquivos, que podem ser encontrados na pasta `src/large_language_model`, sendo o arquivo principal o [client.py](src/large_language_model/client.py)

<p align="center">
  <img src="assets/readme/dashboard/assistente_virtual.JPG" alt="assistente_virtual" border="0" width=70% height=70%>
</p>

O usu√°rio poder√° interagir normalmente com o assistente virtual, que ir√° gerar posts informativos com base no solicitado.

<p align="center">
  <img src="assets/readme/dashboard/criar_post.JPG" alt="criar_post" border="0" width=70% height=70%>
</p>

O agente tamb√©m pode ser instru√≠do a gerar e anexar imagens aos posts, com o objetivo de ilustrar as informa√ß√µes transmitidas e ampliar o impacto visual das mensagens de alerta.

<p align="center">
  <img src="assets/readme/dashboard/criar_imagem_1.JPG" alt="criar_imagem_1" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/criar_imagem_2.JPG" alt="criar_imagem_2" border="0" width=70% height=70%>
</p>

> **Nota**
> Em algumas situa√ß√µes, o agente pode n√£o gerar a imagem diretamente, mas apenas sugerir o prompt de cria√ß√£o. Nesses casos, basta informar ao agente que o prompt est√° aprovado e solicitar a gera√ß√£o da imagem, conforme demonstrado anteriormente.

Por fim, tamb√©m √© poss√≠vel solicitar ao agente que salve o post criado. O conte√∫do ser√° armazenado no banco de dados e poder√° ser visualizado posteriormente no dashboard.

<p align="center">
  <img src="assets/readme/dashboard/salvar_post.JPG" alt="salvar_post" border="0" width=70% height=70%>
</p>

## Previs√£o do tempo e de enchentes

O gente de IA tamb√©m √© capaz de coletar dados meteorol√≥gicos e prever condi√ß√µes clim√°ticas, como enchentes, utilizando a API do OpenWeather. O usu√°rio pode solicitar informa√ß√µes sobre o clima atual e previs√µes para os pr√≥ximos dias.
A l√≥gica utilizada para a previs√£o de enchentes pode ser encontrada no arquivo [realizar_previsao_func_full.py](src/modelo_preditivo/realizar_previsao_func_full.py)

<p align="center">
  <img src="assets/readme/dashboard/previsao_do_tempo.JPG" alt="previsao_do_tempo" border="0" width=70% height=70%>
</p>

> Para obter a previs√£o do tempo, o agente utiliza a API do OpenWeather, que fornece dados atualizados sobre as condi√ß√µes clim√°ticas em tempo real.

<p align="center">
  <img src="assets/readme/dashboard/previsao_de_enchentes.JPG" alt="previsao_de_enchentes" border="0" width=70% height=70%>
</p>

> **ATEN√á√ÉO**
> A previs√£o de enchentes √© baseada nas leituras dos sensores e no modelo de IA treinado pelo grupo, que ser√° detalhado a seguir. O Agente de IA utiliza uma ferramenta (tool) que tem acesso ao modelo preditivo de enchentes e, em seguida, repassa a resposta ao usu√°rio.

## Poss√≠veis erros ao interagir com o agente

O projeto utiliza uma chave de API para desenvolvedores do Google, a qual pode ter limita√ß√µes de uso. 
Caso o usu√°rio encontre erros ao interagir com o agente, como mensagens de falha ou problemas na gera√ß√£o de posts, √© poss√≠vel que a chave tenha atingido o limite de requisi√ß√µes.
Para resolver esse problema, o usu√°rio pode tentar novamente mais tarde ou utilizar uma chave de API pr√≥pria, conforme explicado na se√ß√£o "Arquivo de Configura√ß√£o".
O limite de requisi√ß√µes da API √© de 60 requisi√ß√µes por minuto e 1500 requisi√ß√µes por dia. Entretanto, os modelos podem ficar indispon√≠veis ao longo do dia, dependendo do volume de usu√°rios que est√£o utilizando a API.

<p align="center">
  <img src="assets/readme/dashboard/erro_503.JPG" alt="erro_503" border="0" width=70% height=70%>
</p>

## Poss√≠veis alucina√ß√µes que o agente pode ter

O agente n√£o √© perfeito e pode apresentar alucina√ß√µes ‚Äî ou seja, gerar informa√ß√µes incorretas, irrelevantes ou at√© mesmo come√ßar a responder em ingl√™s.
Isso pode ocorrer devido a limita√ß√µes do modelo de IA ou √† forma como o prompt foi interpretado pelo agente.
Caso isso ocorra, a melhor solu√ß√£o √© clicar no bot√£o "Novo Chat" e iniciar uma nova conversa.

## Menus CRUD

Os menus CRUD s√£o criados de maneira automatizada a partir dos Models citados anteriormente. A l√≥gica de sua cria√ß√£o pode ser encontrada na pasta `src/dashboard/generic`, como por exemplo o arquivo [table_view.py](src/dashboard/generic/table_view.py).

## Visualizando e alterando imagens criadas

As imagens geradas pelo agente de IA podem ser visualizadas e editadas diretamente no dashboard. O usu√°rio pode acessar a p√°gina de Arquivos, onde poder√° visualizar todas as imagens criadas, al√©m de editar ou excluir aquelas que n√£o forem mais necess√°rias.


<p align="center">
  <img src="assets/readme/dashboard/crud/arquivos.JPG" alt="arquivos" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/crud/pagina_visualizacao_arquivos.JPG" alt="pagina_visualizacao_arquivos" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/crud/criar_editar_arquivos.JPG" alt="criar_editar_arquivos" border="0" width=70% height=70%>
</p>

Para salvar um novo arquivo, o usu√°rio pode clicar no bot√£o "Novo", preencher o formul√°rio e clicar em "Salvar". O arquivo ser√° adicionado √† lista de arquivos e poder√° ser utilizado posteriormente na cria√ß√£o de posts.

<p align="center">
  <img src="assets/readme/dashboard/crud/criar_arquivo.JPG" alt="criar_arquivo" border="0" width=70% height=70%>
</p>

Para editar um arquivo existente, o usu√°rio pode selecionar um arquivo da lista e clicar no bot√£o "Editar", fazer as altera√ß√µes necess√°rias e clicar em "Salvar". O arquivo ser√° atualizado na lista de arquivos.

<p align="center">
  <img src="assets/readme/dashboard/crud/editar_arquivo_1.JPG" alt="editar_arquivo_1" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/crud/editar_arquivo_2.JPG" alt="editar_arquivo_1" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/crud/editar_arquivo_3.JPG" alt="editar_arquivo_1" border="0" width=70% height=70%>
</p>

Para excluir um arquivo, o usu√°rio pode selecionar um arquivo da lista e clicar no bot√£o "Editar" e posteriormente "Excluir". O arquivo ser√° removido da lista de arquivos.

<p align="center">
  <img src="assets/readme/dashboard/crud/excluir_1.JPG" alt="excluir_1" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/crud/excluir_2.JPG" alt="excluir_2" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/crud/excluir_3.JPG" alt="excluir_3" border="0" width=70% height=70%>
</p>

## Visualizando e alterando posts criados

A l√≥gica de visualiza√ß√£o e altera√ß√£o dos posts criados segue a mesma estrutura utilizada para os arquivos. O usu√°rio pode acessar a p√°gina "Posts", onde √© poss√≠vel visualizar todos os conte√∫dos previamente gerados, al√©m de realizar a√ß√µes como edi√ß√£o ou exclus√£o daqueles que n√£o forem mais necess√°rios.
Posto isto, seguem abaixo algumas imagens que ilustram a interface da p√°gina de posts, incluindo as funcionalidades de visualiza√ß√£o e edi√ß√£o dos conte√∫dos criados.

<p align="center">
  <img src="assets/readme/dashboard/crud/posts_1.JPG" alt="posts_1" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/crud/posts_2.JPG" alt="posts_2" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/crud/posts_3.JPG" alt="posts_3" border="0" width=70% height=70%>
</p>

## Visualizando e alterando sensores e leituras

Os sensores podem ser localizados no menu sob a sess√£o de sensores, nele o usu√°rio poder√° visualizar todos os sensores cadastrados, bem como as leituras realizadas por cada um deles.
O usuario tamb√©m poder√° realizar opera√ß√µes CRUD na mesma maneira do anteriormente citado.

<p align="center">
  <img src="assets/readme/dashboard/sensores/menu_sensores.JPG" alt="menu_sensores" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/sensores/menu_sensores_2.JPG" alt="menu_sensores_2" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/sensores/menu_sensores_3.JPG" alt="menu_sensores_3" border="0" width=70% height=70%>
</p>

No caso das leituras, o usu√°rio poder√° visualizar um gr√°fico com as leituras realizadas por cada sensor, podendo visualizar um gr√°fico com dados reais ou simulados.

<p align="center">
  <img src="assets/readme/dashboard/sensores/menu_sensores_4.JPG" alt="menu_sensores_4" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/sensores/menu_sensores_5.JPG" alt="menu_sensores_5" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/sensores/menu_sensores_6.JPG" alt="menu_sensores_6" border="0" width=70% height=70%>
</p>

## Importar Tabelas com os dados

As tabelas com os dados utilizados no sistema podem ser encontradas na pasta em `assets/database_export.zip`.

O arquivo zip cont√©m os arquivos no formato CSV, que podem ser importados para o banco de dados utilizando o dashboard, conforme passos abaixo.

1. O usu√°rio deve selecionar a op√ß√£o "Importar Banco de Dados" no menu principal.
<p align="center">
  <img src="assets/readme/dashboard/importar_banco_de_dados/importar_bd_1.JPG" alt="importar_db" border="0" width=80% height=80%>
</p>

2. Selecione o arquivo ZIP localizado em `assets/database_export.zip`, espere carregar, role a p√°gina at√© o final e clique no bot√£o "Salvar no Banco de Dados".
<p align="center">
  <img src="assets/readme/dashboard/importar_banco_de_dados/importar_bd_2.JPG" alt="salvar_db" border="0" width=80% height=80%>
</p>

3. N√£o feche a janela e espere a opera√ß√£o ser conclu√≠da. Ap√≥s a conclus√£o, o sistema ir√° exibir uma mensagem de sucesso. Caso ocorra algum erro, tente novamente.

<p align="center">
  <img src="assets/readme/dashboard/importar_banco_de_dados/importar_bd_3.JPG" alt="salvar_db" border="0" width=80% height=80%>
</p>


## Previs√£o do tempo

O usuario tamb√©m pode acessar a p√°gina de Previs√£o do Tempo, onde poder√° visualizar as condi√ß√µes clim√°ticas atuais e as previs√µes para os pr√≥ximos dias.

<p align="center">
  <img src="assets/readme/dashboard/view_previsao_do_tempo.JPG" alt="view_previsao_do_tempo" border="0" width=70% height=70%>
</p>

## Modelo de IA para a previs√£o de enchentes

O tema escolhido pelo grupo para o desenvolvimento do modelo de Intelig√™ncia Artificial foi a previs√£o de enchentes, considerando que este √© um dos desastres naturais mais recorrentes no Brasil, com alto potencial de causar danos significativos √† popula√ß√£o.

O agente de IA possui acesso direto ao modelo preditivo treinado pelo grupo, o qual foi desenvolvido com base em dados reais provenientes da Ag√™ncia Nacional de √Åguas e Saneamento B√°sico (ANA). Os dados utilizados referem-se a s√©ries hist√≥ricas de n√≠veis e vaz√µes de esta√ß√µes hidrol√≥gicas em todo o pa√≠s, e est√£o dispon√≠veis publicamente no reposit√≥rio oficial da ANA, acess√≠vel por meio do seguinte link:

üîó https://github.com/anagovbr/hidro-dados-estacoes-convencionais

Para mais informa√ß√µes sobre a origem e confiabilidade da base de dados, pode-se consultar a publica√ß√£o oficial da Ag√™ncia Brasil:

üìÑ https://agenciagov.ebc.com.br/noticias/202310/agencia-disponibiliza-series-historicas-de-dados-de-niveis-e-vazoes-de-estacoes-em-todo-o-pais 

Para realizar a previs√£o, o modelo utiliza as leituras mais recentes dos sensores de n√≠vel de √°gua e das condi√ß√µes ambientais da regi√£o. Com base nessas informa√ß√µes, ele estima a probabilidade de ocorr√™ncia de enchentes em determinado local.

Al√©m da integra√ß√£o com o agente, o usu√°rio tamb√©m pode realizar previs√µes diretamente por meio do dashboard interativo.

A seguir, apresenta-se a visualiza√ß√£o explorat√≥ria da base de dados utilizada no treinamento do modelo de IA.

<p align="center">
  <img src="assets/readme/dashboard/modelo_preditivo/exploracao_dados_1.JPG" alt="exploracao_dados_1" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/modelo_preditivo/exploracao_dados_2.JPG" alt="exploracao_dados_2" border="0" width=70% height=70%>
</p>
<p align="center">
  <img src="assets/readme/dashboard/modelo_preditivo/exploracao_dados_3.JPG" alt="exploracao_dados_3" border="0" width=70% height=70%>
</p>

Por fim, a view onde o usu√°rio pode realizar a previs√£o de enchentes, que utiliza o modelo de IA treinado pelo grupo.

<p align="center">
  <img src="assets/readme/dashboard/modelo_preditivo/previsao_de_enchentes_manual.JPG" alt="previsao_de_enchentes_manual" border="0" width=70% height=70%>
</p>


## ‚öôÔ∏è Treinamento do Modelo de Previs√£o [treinamento_modelo.py](src/modelo_preditivo/treinamento_modelo.py)

A constru√ß√£o do modelo de machine learning iniciou-se com a **importa√ß√£o das bibliotecas necess√°rias** para todas as fases de an√°lise: desde a **leitura e manipula√ß√£o de tabelas** (usando **pandas** e **numpy**), passando pela **visualiza√ß√£o preliminar de dados** (com **matplotlib** e **seaborn**), at√© o **pr√©-processamento e a modelagem em si** (com classes de scikit-learn como **StandardScaler**, **LabelEncoder**, **OneHotEncoder**, **StratifiedKFold** e diversos classificadores). Tamb√©m trouxemos utilit√°rios como **joblib** para **salvar artefatos** (modelos, scalers e label encoders) e m√≥dulos padr√£o como **random**, **time** e **os** para **controle de aleatoriedade**, **medi√ß√£o de tempo** e **manipula√ß√£o de arquivos**.

Logo ap√≥s agrupar todas essas importa√ß√µes, definimos o caminho para o arquivo CSV que armazena as medi√ß√µes de **‚ÄúCota‚Äù** (n√≠vel da √°gua), **‚ÄúChuva‚Äù** e **‚ÄúData‚Äù** ‚Äî esse arquivo recebeu o nome de [COTAxCHUVA.csv](src/modelo_preditivo/COTAxCHUVA.csv) e √© carregado em um **DataFrame** (padr√£o do pandas) para facilitar a explora√ß√£o e o tratamento. A partir da√≠, come√ßamos a **entender a distribui√ß√£o da vari√°vel ‚ÄúCota‚Äù**: calculamos os **percentis 90**, **95** e **98** (P90, P95 e P98). Esses valores serviram de refer√™ncia para delimitar **tr√™s faixas cr√≠ticas** que depois se tornariam **r√≥tulos de ‚Äún√≠vel de inunda√ß√£o‚Äù**:

- Qualquer cota acima de **P98** foi classificada como **‚ÄúInunda√ß√£o prov√°vel‚Äù**.  
- Valores entre **P95 e P98** configuraram o r√≥tulo **‚ÄúAlerta elevado‚Äù**.  
- Aqueles entre **P90 e P95** passaram a ser **‚ÄúSitua√ß√£o de aten√ß√£o‚Äù**.  
- Todos os pontos abaixo de **P90** ficaram em **‚ÄúCondi√ß√µes normais‚Äù**.

Com esses limites em m√£os (definidos no c√≥digo como **315**, **250** e **205**, respectivamente), implementamos a fun√ß√£o **classificar_nivel(cota)** que, para cada valor de cota, retornava um dos quatro r√≥tulos mencionados. Aplicamos essa fun√ß√£o diretamente ao **DataFrame**, criando a coluna **Nivel**, que se tornou nossa **vari√°vel alvo** para o problema de classifica√ß√£o.

Em seguida, conduziu-se uma **inspe√ß√£o inicial**: exibimos as primeiras linhas com **df.head()** e consultamos a estrutura de tipos e presen√ßa de valores nulos com **df.info()**. Para garantir que nenhum dado faltante interrompesse a modelagem, executamos **df.isnull().sum()** e usamos interpola√ß√£o pelo m√©todo **‚Äúnearest‚Äù** para preencher eventuais **NaNs**. Assim que confirmamos que n√£o havia mais valores ausentes, identificamos registros duplicados com **df.duplicated().sum()**, exibimos quantos existiam (no notebook original apenas imprimimos esse total) e pudemos optar por remover ou manter duplicatas conforme o contexto. A seguir, avaliamos a presen√ßa de **outliers** em **‚ÄúCota‚Äù** e **‚ÄúChuva‚Äù** definindo **limites l√≥gicos** (por exemplo, **‚ÄúCota‚Äù** entre **50 e 500**; **‚ÄúChuva‚Äù** entre **0 e 300**). Ao filtrar pontos fora desses intervalos, conseguimos visualizar quantas amostras estavam fora do padr√£o e, se necess√°rio, trat√°-las antes da modelagem. Para complementar, exibimos as estat√≠sticas descritivas b√°sicas do conjunto com **df.describe()**, conferindo **m√©dia**, **mediana**, **desvio padr√£o** e **quartis** para as vari√°veis num√©ricas.

Quando chegamos √† coluna **Nivel**, vimos quantas inst√¢ncias havia em cada categoria por meio de **df['Nivel'].value_counts()**. Esse passo √© importante para detectar **desequil√≠brio entre classes** ‚Äî por exemplo, se a maioria dos registros se concentrasse em **‚ÄúCondi√ß√µes normais‚Äù** e houvesse poucas amostras em **‚ÄúInunda√ß√£o prov√°vel‚Äù**. Caso o desbalanceamento fosse muito grave, considerar√≠amos t√©cnicas como **oversampling** ou **undersampling**, mas nesse caso inicial seguimos sem ajustes extras.

Chegou o momento de **separar vari√°veis preditoras de vari√°vel alvo**: descartamos a coluna **Nivel** de nosso conjunto **X**, restando apenas **‚ÄúCota‚Äù** e **‚ÄúChuva‚Äù** (e, caso necess√°rio, engenharias de atributos de data). A vari√°vel **y** passou a ser **df['Nivel']**. Para que os classificadores entendessem os r√≥tulos, aplicamos o **LabelEncoder**, convertendo as categorias de texto em n√∫meros (por exemplo, **‚ÄúCondi√ß√µes normais‚Äù** ‚Üí **0**, **‚ÄúSitua√ß√£o de aten√ß√£o‚Äù** ‚Üí **1**, etc.). O **DataFrame** foi atualizado com a nova coluna num√©rica, substituindo os nomes de r√≥tulo pela vers√£o codificada.

Com **X e y ajustados**, dividimos o dataset em **conjuntos de treinamento e teste** na propor√ß√£o de **80/20**, utilizando **train_test_split(..., stratify=y)**. A estratifica√ß√£o garantiu que a propor√ß√£o de exemplos de cada classe se mantivesse aproximadamente igual em ambos os conjuntos, o que evita que um modelo seja treinado sem nenhuma inst√¢ncia de **‚ÄúInunda√ß√£o prov√°vel‚Äù**, por exemplo.

Antes de alimentar os classificadores, aplicamos o **MinMaxScaler** em **X_train** e **X_test** para que todas as vari√°veis ficassem no intervalo de **0 a 1** ‚Äî essencial para algoritmos sens√≠veis √† escala, como **KNN** e **SVM**. Depois desse escalonamento, garantimos que **y_train** e **y_test** fossem estruturas unidimensionais de inteiros.

Para avaliar de forma justa cada modelo, constru√≠mos um esquema de **valida√ß√£o cruzada estratificada** com **5 folds** (**StratifiedKFold(n_splits=5, shuffle=True, random_state=42)**). Esse procedimento divide repetidamente o conjunto de treinamento em cinco partes, treinando e validando em combina√ß√µes diferentes para obter uma m√©dia mais robusta de desempenho.

A parte de **instancia√ß√£o dos modelos** √© bastante ampla: geramos aleatoriamente varia√ß√µes de hiperpar√¢metros para cerca de **20 classificadores diferentes**, incluindo **Regress√£o Log√≠stica**, **√Årvores de Decis√£o**, **Random Forest**, **Gradient Boosting**, **ExtraTrees**, **AdaBoost**, **Bagging** (com base em **Decision Tree**), **SVM** (com kernels variados), **KNN** (com diferentes k), **Naive Bayes**, **MLP** (com arquiteturas distintas), **LDA**, **QDA** e modelos calibrados via **CalibratedClassifierCV**. Para cada modelo, criamos um nome √∫nico que incorpora seus hiperpar√¢metros (por exemplo, **‚ÄúRandForest 150‚Äù** ou **‚ÄúSVM rbf‚Äù**), evitando repeti√ß√µes de inst√¢ncias e garantindo que pud√©ssemos comparar configura√ß√µes distintas em um √∫nico experimento.

O **la√ßo de treinamento** percorre essa lista de tuplas (nome, modelo). Para cada par, registramos o hor√°rio de in√≠cio, chamamos **modelo.fit(X_train, y_train)** e, logo em seguida, usamos **modelo.predict(X_test)** para gerar as predi√ß√µes no conjunto de teste. Tamb√©m tentamos obter **probabilidades de predi√ß√£o** (**predict_proba**) para calcular o **ROC AUC** ‚Äî no caso de problemas bin√°rios, usamos a probabilidade da classe positiva; em multiclasse, aplicamos o modo **‚Äúone-vs-rest‚Äù**. Se o m√©todo **predict_proba** n√£o fosse suportado, atribu√≠amos **None** para a m√©trica **AUC**. O **tempo total de treinamento** (em segundos) foi calculado subtraindo o tempo de t√©rmino menos o tempo de in√≠cio.

Depois de treinar e avaliar cada modelo, guardamos em um dicion√°rio uma linha contendo as m√©tricas:

- **Accuracy** (acur√°cia simples)  
- **Precision** (m√©dia ponderada, com **zero_division=0**)  
- **Recall** (m√©dia ponderada)  
- **F1 Score** (m√©dia ponderada)  
- **ROC AUC** (onde dispon√≠vel)

Registramos o **tempo de treinamento** em uma lista separada, construindo posteriormente o **DataFrame df_tempos** com cada par (**nome do modelo**, **tempo em segundos**).

Ap√≥s concluir o ciclo para todos os modelos, transformamos a lista de resultados em um DataFrame chamado **atual_resultados**, ordenando-o de forma decrescente por **F1 Score**. Consequentemente, **atual_resultados** exibe um **ranking completo** de todos os **20 modelos** testados, das **melhores** √†s **piores performances**. Paralelamente, montamos **df_tempos** para comparar visualmente a efici√™ncia no treinamento.

Para gerar as **visualiza√ß√µes comparativas**, implementamos a fun√ß√£o **exibir_metricas(df_resultados, df_tempos)**. Nela, constru√≠mos tr√™s gr√°ficos:

- **Barplot de F1 Score** para todos os modelos, onde cada barra apresenta o valor do F1 Score obtido no teste.  
- **Heatmap** com o conjunto de m√©tricas (**acur√°cia**, **precis√£o**, **recall**, **F1 Score** e **ROC AUC**) para todos os modelos, facilitando a an√°lise de trade-offs entre diferentes desempenhos.  
- **Barplot de tempo de treinamento** por modelo, demonstrando o custo computacional associado a cada algoritmo e configura√ß√£o.

Assim, conseguimos visualizar de forma clara quais modelos n√£o s√≥ apresentam melhor equil√≠brio entre **precis√£o** e **recall**, mas tamb√©m quais exigem menos **tempo de processamento**.

Na **segunda parte do notebook**, focamos na **manuten√ß√£o de um hist√≥rico dos 5 melhores modelos**. Primeiro, verificamos se j√° existia o arquivo **melhores_modelos.csv**. Se ele existisse, carreg√°vamos seu conte√∫do em um DataFrame, un√≠amos (concaten√°vamos) com os resultados atuais (**atual_resultados**) e, em seguida, orden√°vamos tudo por **F1 Score** de forma decrescente. **Duplicatas** pelo **nome do modelo** eram removidas, de modo a manter apenas vers√µes √∫nicas de cada configura√ß√£o. Por fim, mant√≠nhamos os **5 primeiros registros**, salvando essa sele√ß√£o novamente em **melhores_modelos.csv**.

Com os nomes dos **top 5** selecionados, criamos (caso n√£o existisse) a pasta **modelos_salvos/** e, para cada modelo do **top 5**, geramos um arquivo **.pkl** por meio de **joblib.dump()**. Cada arquivo armazenava um dicion√°rio com tr√™s chaves:

- **‚Äòmodelo‚Äô**: o objeto do pr√≥prio classificador treinado;  
- **‚Äòscaler‚Äô**: o **MinMaxScaler** usado no pr√©-processamento;  
- **‚Äòlabel_encoder‚Äô**: o **LabelEncoder** utilizado para convergir as categorias de r√≥tulo em inteiros.

Esse passo garante que, ao recarregar um desses arquivos no futuro, teremos **tudo** o que precisamos para **replicar o pipeline de entrada** (**transforma√ß√£o dos atributos** e **invers√£o dos r√≥tulos**).

Em seguida, reconstru√≠mos dois DataFrames:

- **top5_resultados** cont√©m as linhas de **atual_resultados** filtradas apenas pelos cinco modelos selecionados.  
- **top5_tempos** resulta da jun√ß√£o de **df_tempos** com esses cinco nomes, permitindo ordenar e exibir corretamente o **tempo de treinamento** de cada um deles.

Para esses **top 5**, geramos **tr√™s novas visualiza√ß√µes** espec√≠ficas:

- **Barplot do F1 Score (Top 5)**, ressaltando as diferen√ßas sutis entre as performances dos melhores modelos.  
- **Heatmap (Top 5)** contendo as m√©tricas de cada um desses cinco, para compara√ß√£o detalhada.  
- **Barplot de tempo de treinamento (Top 5)**, expondo qual modelo se mostrou mais r√°pido para treinar, sem abrir m√£o da qualidade na predi√ß√£o.

Por fim, imprimimos um **relat√≥rio detalhado** para cada modelo do **Top 5**. Para cada nome:

- Tentamos carreg√°-lo diretamente da **mem√≥ria** (caso ainda estivesse em **modelos_treinados**) ou, se n√£o estivesse, buscamos o arquivo **.pkl** em disco. Se o arquivo n√£o fosse encontrado, avis√°vamos que aquele modelo espec√≠fico n√£o estava dispon√≠vel para avalia√ß√£o.  
- Geramos predi√ß√µes em **X_test** com **modelo.predict(X_test)** (caso ainda n√£o as tiv√©ssemos em **y_preds**) e, em seguida, comparamos **y_test_labels** e **y_pred_labels**.  
- Impress√£o das **m√©tricas globais**: **Acur√°cia**, **Precis√£o (weighted)**, **Revoca√ß√£o (weighted)** e **F1 Score (weighted)**.  
- Exibi√ß√£o do **‚Äúclassification_report‚Äù** completo, apresentando **precis√£o**, **recall** e **f1-score** por classe.

Dessa maneira, este detalhamento textual pode ser incorporado ao **README** de sua aplica√ß√£o, oferecendo uma **vis√£o completa e passo a passo** de como o **modelo de previs√£o** foi constru√≠do, avaliado e salvo.


## üìÅ Estrutura de pastas

Dentre os arquivos e pastas presentes na raiz do projeto, definem-se:

- <b>.streamlit</b>: Pasta que cont√©m arquivos de configura√ß√£o do Streamlit, como o tema da interface e a organiza√ß√£o da barra lateral.
- <b>assets</b>: Diret√≥rio destinado ao armazenamento de elementos n√£o estruturados do projeto, como imagens e √≠cones utilizados no dashboard.
- <b>src</b>: Diret√≥rio principal que cont√©m todo o c√≥digo-fonte desenvolvido ao longo das fases do projeto. Ele est√° organizado nos seguintes subm√≥dulos:
  - <b>api_metereologica</b>: Cont√©m o c√≥digo respons√°vel por interagir com a API p√∫blica de previs√£o do tempo, coletando dados meteorol√≥gicos externos. ([api_metereologica](src/api_metereologica/))
  - <b>dashboard</b>: C√≥digo respons√°vel pela constru√ß√£o do dashboard, desenvolvido em Python com uso da biblioteca Streamlit. ([dashboard](src/dashboard/))
  - <b>database</b>: M√≥dulo respons√°vel pelas opera√ß√µes de banco de dados, incluindo conex√µes, inser√ß√µes, listagens, edi√ß√µes e exclus√µes de registros.
  - <b>large_language_model</b>: Cont√©m o c√≥digo do agente de IA, que √© respons√°vel por gerar posts informativos e interagir com o usu√°rio. Este m√≥dulo inclui a l√≥gica de gera√ß√£o de posts, bem como a integra√ß√£o com o modelo de previs√£o de enchentes.
  - <b>logger</b>: C√≥digo respons√°vel por registrar (logar) todas as opera√ß√µes executadas no sistema, garantindo rastreabilidade.
  - <b>modelo_preditivo</b>: Cont√©m o c√≥digo do modelo de previs√£o de enchentes, incluindo o treinamento do modelo e a l√≥gica de previs√£o. Este m√≥dulo √© respons√°vel por analisar os dados hist√≥ricos de n√≠veis de √°gua e condi√ß√µes ambientais para prever poss√≠veis enchentes.
  - <b>plots</b>: Cont√©m o c√≥digo respons√°vel pela gera√ß√£o de gr√°ficos e visualiza√ß√µes, utilizado para exibir dados de forma clara e intuitiva no dashboard.
  - <b>services</b>: Cont√©m o c√≥digo respons√°vel por servi√ßos auxiliares.
  - <b>wokwi</b>: Cont√©m o c√≥digo do sensor ESP32 utilizado na simula√ß√£o de sensores de n√≠vel de rios e condi√ß√µes ambientais, com foco na previs√£o de enchentes em regi√µes monitoradas.
  - <b>wokwi_api</b>: Cont√©m o c√≥digo respons√°vel por criar a API que vai salvar as leituras dos sensores no banco de dados, permitindo a integra√ß√£o entre o sensor e o sistema de previs√£o de enchentes.
- <b>.env</b>: Arquivo de configura√ß√£o que cont√©m as chaves de API e outras vari√°veis de ambiente necess√°rias para o funcionamento do sistema. √â necess√°rio criar este arquivo na raiz do projeto, conforme orienta√ß√µes na se√ß√£o "Arquivo de Configura√ß√£o".
- <b>.gitignore</b>: Arquivo que especifica quais arquivos e pastas devem ser ignorados pelo Git, evitando que informa√ß√µes sens√≠veis ou desnecess√°rias sejam versionadas. √â importante garantir que o arquivo `.env` esteja inclu√≠do neste arquivo para evitar o upload de chaves de API e outras informa√ß√µes sens√≠veis.
- <b>README</b>: Arquivo de documenta√ß√£o do projeto (este que est√° sendo lido), com orienta√ß√µes gerais, instru√ß√µes de uso e contextualiza√ß√£o.
- <b>main_dash</b>: Arquivo principal para a execu√ß√£o do dashboard. Est√° localizado na raiz do projeto com o objetivo de evitar problemas com importa√ß√µes de m√≥dulos internos.
- - <b>requirements.txt</b>: Arquivo que lista todas as depend√™ncias do projeto, necess√°rio para a instala√ß√£o do ambiente virtual. Deve ser utilizado com o comando `pip install -r requirements.txt` para instalar as bibliotecas necess√°rias.

## üóÉ Hist√≥rico de versionamento

* **0.5.0 - 06/06/2025** ‚Äì README vers√£o final  
* **0.4.0 - 05/06/2025** ‚Äì Revis√£o completa e formaliza√ß√£o do README:  
  - Corre√ß√µes gramaticais e de concord√¢ncia;
  - Aprimoramento do texto para maior clareza e formalidade;
  - Documenta√ß√£o da instala√ß√£o, execu√ß√£o e uso do `.env`; 
  - Explica√ß√µes detalhadas sobre poss√≠veis erros, limita√ß√µes e alucina√ß√µes do agente de IA;
  - Inclus√£o dos links oficiais da base de dados utilizada no modelo de previs√£o de enchentes;
  - Atualiza√ß√£o da se√ß√£o de estrutura de pastas;
  - Adi√ß√£o do t√≥pico "Treinamento do Modelo de Previs√£o" descrevendo o processo de treinamento realizado;
  - Adi√ß√£o do t√≥pico "Pr√≥ximos Passos e Vis√£o Futura" com foco na expans√£o para aplicativo m√≥vel, detalhando funcionalidades planejadas para aumentar o alcance e a usabilidade do sistema.
* **0.3.0 - 05/06/2025** ‚Äì Melhorias no readme, adi√ß√£o de imagens e explica√ß√µes sobre os sensores e importa√ß√£o de banco de dados  
* **0.2.0 - 04/06/2025** ‚Äì Vers√£o preliminar da nossa aplica√ß√£o, com dashboard e funcionalidades b√°sicas implementadas  
* **0.1.0 - 26/06/2025** ‚Äì Vers√£o preliminar da nossa aplica√ß√£o

## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> est√° licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>